# Vector Search Configuration for ArangoDB

This document explains how to configure ArangoDB for vector-based entity resolution using the `VectorBlockingStrategy`.

## Overview

Vector search enables semantic similarity matching by comparing embedding vectors of database records. This is implemented as **Tier 3 (vector blocking)** that complements exact (Tier 1) and fuzzy text (Tier 2) blocking.

## Prerequisites

1. **Python Packages**: Install sentence-transformers and torch
   ```bash
   pip install sentence-transformers>=2.2.0 torch>=2.0.0
   ```

2. **ArangoDB Version**: 3.9+ (3.10+ recommended for optimal performance)

3. **Embeddings**: Records must have pre-computed embeddings stored in a field (default: `embedding_vector`)

## Quick Start

### Step 1: Generate Embeddings

Use the `EmbeddingService` to generate embeddings for your collection:

```python
from entity_resolution.services.embedding_service import EmbeddingService

# Initialize the service
embedding_service = EmbeddingService(
    model_name='all-MiniLM-L6-v2',  # Fast, 384-dim embeddings
    device='cpu'  # or 'cuda' for GPU
)

# Generate embeddings for all documents
stats = embedding_service.ensure_embeddings_exist(
    collection_name='customers',
    text_fields=['name', 'company', 'address', 'email']
)

print(f"Generated {stats['generated']} embeddings")
```

### Step 2: Use Vector Blocking

Once embeddings exist, use `VectorBlockingStrategy` to find similar records:

```python
from entity_resolution.strategies import VectorBlockingStrategy

# Create the strategy
strategy = VectorBlockingStrategy(
    db=db,
    collection='customers',
    similarity_threshold=0.7,  # Minimum cosine similarity (0-1)
    limit_per_entity=20        # Max candidates per record
)

# Generate candidate pairs
pairs = strategy.generate_candidates()

print(f"Found {len(pairs)} candidate pairs")
for pair in pairs[:5]:
    print(f"  {pair['doc1_key']} <-> {pair['doc2_key']} "
          f"(similarity: {pair['similarity']:.3f})")
```

## Embedding Models

### Recommended Models

| Model | Dim | Speed | Quality | Use Case |
|-------|-----|-------|---------|----------|
| `all-MiniLM-L6-v2` | 384 | Fast | Good | Default, general purpose |
| `all-mpnet-base-v2` | 768 | Moderate | Excellent | High accuracy needed |
| `all-distilroberta-v1` | 768 | Moderate | Very Good | Balance speed/quality |

### Choosing a Model

```python
# Fast and efficient (recommended for most cases)
embedding_service = EmbeddingService(model_name='all-MiniLM-L6-v2')

# Best quality, slower
embedding_service = EmbeddingService(model_name='all-mpnet-base-v2')
```

## Similarity Threshold Tuning

The `similarity_threshold` parameter controls how similar records must be to become candidates:

- **0.9-1.0**: Very similar (likely duplicates, high precision)
- **0.8-0.9**: Similar (possible duplicates, balanced)
- **0.7-0.8**: Somewhat similar (more candidates, high recall)
- **Below 0.7**: Low similarity (too many false positives)

### Finding the Right Threshold

Use the `get_similarity_distribution()` method to analyze your data:

```python
stats = strategy.get_similarity_distribution(sample_size=1000)

print(f"Mean similarity: {stats['mean_similarity']:.3f}")
print(f"Recommended thresholds:")
print(f"  Conservative (top 10%): {stats['recommended_thresholds']['conservative']:.3f}")
print(f"  Balanced (top 25%): {stats['recommended_thresholds']['balanced']:.3f}")
print(f"  Aggressive (top 50%): {stats['recommended_thresholds']['aggressive']:.3f}")
```

## Configuration Options

### Basic Configuration

```python
strategy = VectorBlockingStrategy(
    db=db,
    collection='customers',
    
    # Embedding configuration
    embedding_field='embedding_vector',  # Where embeddings are stored
    
    # Matching configuration
    similarity_threshold=0.7,  # Minimum cosine similarity
    limit_per_entity=20,       # Max candidates per document
    
    # Optional: Additional blocking
    blocking_field='state',    # Only compare within same state
    
    # Optional: Filters
    filters={
        'name': {'not_null': True, 'min_length': 3},
        'status': {'equals': 'active'}
    }
)
```

### Advanced: Geographic Blocking

Combine vector search with geographic constraints:

```python
# Only find similar customers within the same state
strategy = VectorBlockingStrategy(
    db=db,
    collection='customers',
    similarity_threshold=0.7,
    blocking_field='state'  # Geographic blocking
)
```

## Data Storage Format

### Document Structure with Embeddings

```javascript
{
  "_key": "cust_001",
  "_id": "customers/cust_001",
  
  // Original fields
  "name": "John Smith",
  "company": "Acme Corp",
  "address": "123 Main St, New York, NY",
  "email": "john.smith@acme.com",
  
  // Embedding field (generated by EmbeddingService)
  "embedding_vector": [0.12, -0.45, 0.78, ...],  // 384-dim or 768-dim
  
  // Metadata (automatically added)
  "embedding_metadata": {
    "model": "all-MiniLM-L6-v2",
    "dim": 384,
    "timestamp": "2025-12-09T10:30:00Z",
    "version": "v1.0"
  }
}
```

## Performance Considerations

### Memory Usage

Embeddings require storage space:

- **384-dim**: ~1.5 KB per document
- **768-dim**: ~3 KB per document

For 1 million documents:
- 384-dim: ~1.5 GB
- 768-dim: ~3 GB

### Generation Time

Embedding generation is a one-time cost:

- **CPU**: ~100-500 docs/second
- **GPU**: ~1000-5000 docs/second

Use batch processing for large collections:

```python
stats = embedding_service.ensure_embeddings_exist(
    collection_name='customers',
    text_fields=['name', 'company', 'address'],
    batch_size=100  # Process in batches of 100
)
```

### Query Performance

Vector similarity queries scale with:
- Number of documents
- Embedding dimensionality
- Similarity threshold (lower = more comparisons)

**Optimization tips**:
1. Use `blocking_field` to reduce search space
2. Choose appropriate `limit_per_entity`
3. Use 384-dim embeddings unless accuracy critical
4. Apply filters to reduce document count

## Advanced: ArangoSearch Optimization (Future)

For ArangoDB 3.10+, you can use ArangoSearch views for faster vector similarity:

```javascript
// Create an ArangoSearch view for vector search
db._createView('customers_vector_view', 'arangosearch', {
  links: {
    customers: {
      fields: {
        embedding_vector: {
          analyzers: ['identity'],
          type: 'array',
          dimensions: 384,
          similarity: 'cosine'
        }
      }
    }
  }
});
```

**Note**: The current `VectorBlockingStrategy` implementation uses a compatibility approach that works across all ArangoDB versions. ArangoSearch optimization is planned for a future release.

## Troubleshooting

### No Embeddings Found

```
RuntimeError: No embeddings found in collection 'customers'
```

**Solution**: Generate embeddings first:
```python
embedding_service.ensure_embeddings_exist('customers', ['name', 'company'])
```

### Out of Memory

```
RuntimeError: CUDA out of memory
```

**Solution**: Use CPU instead:
```python
embedding_service = EmbeddingService(device='cpu')
```

### Slow Performance

**Solutions**:
1. Use smaller embedding model (384-dim instead of 768-dim)
2. Add `blocking_field` to reduce search space
3. Lower `limit_per_entity`
4. Apply more restrictive filters

### Low Quality Results

**Solutions**:
1. Increase `similarity_threshold`
2. Use higher quality model (`all-mpnet-base-v2`)
3. Include more text fields in embedding generation
4. Ensure text fields are clean and normalized

## Integration with Full Pipeline

Vector blocking works seamlessly with other blocking strategies:

```python
from entity_resolution.strategies import (
    CollectBlockingStrategy,
    BM25BlockingStrategy,
    VectorBlockingStrategy
)

# Tier 1: Exact matching (fast, high precision)
tier1 = CollectBlockingStrategy(
    db=db,
    collection='customers',
    blocking_keys=['phone', 'email']
)

# Tier 2: Fuzzy text matching (moderate speed, good precision)
tier2 = BM25BlockingStrategy(
    db=db,
    collection='customers',
    search_fields=['name', 'company']
)

# Tier 3: Semantic similarity (slower, high recall)
tier3 = VectorBlockingStrategy(
    db=db,
    collection='customers',
    similarity_threshold=0.75
)

# Combine all tiers
all_pairs = tier1.generate_candidates()
all_pairs.extend(tier2.generate_candidates())
all_pairs.extend(tier3.generate_candidates())

# Remove duplicates
unique_pairs = {(p['doc1_key'], p['doc2_key']): p for p in all_pairs}.values()
```

## See Also

### Documentation
- **[API Reference](../docs/api/API_REFERENCE.md#embedding-service)** - Complete API documentation for EmbeddingService and VectorBlockingStrategy
- **[CHANGELOG](../CHANGELOG.md)** - Version history and feature updates
- **[Working Example](../examples/vector_blocking_example.py)** - End-to-end demonstration
- **[Code Quality Review](../docs/development/vector-search-code-quality-review.md)** - Security and quality audit

### Research
- **[Ebraheem et al. (2018)](../research/papers/embeddings/2018_Ebraheem_DistributedEntityMatching_notes.md)** - Detailed research notes on tuple embeddings

### External Resources
- **[sentence-transformers](https://www.sbert.net/)** - Pre-trained model library
- **[ArangoDB Documentation](https://www.arangodb.com/docs/stable/)** - Database documentation

## Support

For questions or issues:
1. Check the documentation: `docs/api/API_REFERENCE.md`
2. See examples: `examples/vector_blocking_example.py`
3. Review research notes: `research/papers/embeddings/`

